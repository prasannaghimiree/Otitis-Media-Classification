{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SyXhgXSjgSeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://drive.google.com/file/d/1UGrMGfb9zvbBqOvbV62G-XdUlBIAvOad/view\n",
        "!wget https://drive.google.com/file/d/1jc7Dmp26km0PKRwf9u3Xcyui4SRiojcT/view"
      ],
      "metadata": {
        "id": "XR_TTurfoX7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class_labels= ['N','D','C','A','F','M','O']\n",
        "keyword_label_mapping  = {\n",
        "    'normal':'N',\n",
        "    'retinopathy':'D',\n",
        "    'glaucoma':'G',\n",
        "    'cataract':'C',\n",
        "    'macular degeneration':'A',\n",
        "    'hypertensive':'H',\n",
        "    'myopia':'M',\n",
        "    'lens dust':'O', 'optic disk photographically invisible':'O', 'low image quality':'O', 'image offset':'O'\n",
        "}\n",
        "non_decisive_labels = [\"lens dust\", \"optic disk photographically invisible\", \"low image quality\", \"image offset\"]\n",
        "# if the keyword contains label outside of the above then, label them as others 'O'\n",
        "def get_individual_labels(diagnostic_keywords):\n",
        "    keywords = [ keyword  for keyword in diagnostic_keywords.split(',')]\n",
        "    contains_normal = False\n",
        "    for k in keywords:\n",
        "        for label in keyword_label_mapping.keys():\n",
        "            if label in k:\n",
        "                if label == 'normal':\n",
        "                    contains_normal = True # if found a 'normal' keyword, check if there are other keywords but keep in mind that a normal keyword was found\n",
        "                else:\n",
        "                    return keyword_label_mapping[label] # found a proper keyword label, use the first occurence\n",
        "\n",
        "    # did not find a proper keyword label, see if there are labels other than non-decisive labels, if so, categorize them as 'others'\n",
        "    decisive_label = False\n",
        "    for k in keywords:\n",
        "        if k not in non_decisive_labels and (('normal' not in k) or ('abnormal' in k)):\n",
        "            decisive_label = True\n",
        "    if decisive_label:\n",
        "        # contains decisive label other than the normal and abnormal categories\n",
        "        return 'O'\n",
        "    if contains_normal:\n",
        "        return 'N'\n",
        "    # if any of the above criteria do not match, then return as is\n",
        "    return keywords[0] # u\n",
        "\n",
        "# write test cases\n",
        "# if both left and right are normal, then the final diagnosis is also normal\n",
        "def test_normal(row):\n",
        "    l,r = row['Left-label'], row['Right-label']\n",
        "    if l == 'N' and r == 'N' and row['N'] != 1:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def test_others(row):\n",
        "    l,r = row['Left-label'], row['Right-label']\n",
        "    if row['O'] == 1:\n",
        "        if l == 'O' or r == 'O':\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    return True\n",
        "\n"
      ],
      "metadata": {
        "id": "wuviidFoidy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "# from preprocessing import get_individual_labels, test_normal,test_others\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from pandas import DataFrame\n",
        "from pathlib import Path\n",
        "# from torchvision.transforms import img_transform,crop_nonzero\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from transforms.transforms import\n",
        "# import sys\n",
        "# sys.path.append(\"../\")\n",
        "# import cv2\n",
        "\n",
        "\n",
        "TRAIN_DIR=\"/content/drive/MyDrive\"\n",
        "df=pd.read_excel('/content/drive/MyDrive/ODIR-5K_Training_Annotations(Updated)_V2.xlsx')\n",
        "csv_data= df.to_csv(os.path.join(TRAIN_DIR,\"data.csv\"))\n",
        "\n",
        "Left_eye=df[['Left-Fundus','Left-Diagnostic Keywords']].copy()\n",
        "Left_eye.columns=['Image','Labels']\n",
        "# Left_eye.to_csv(os.path.join(TRAIN_DIR,'left_eye.csv'))\n",
        "\n",
        "Right_eye=df[['Right-Fundus','Right-Diagnostic Keywords']].copy()\n",
        "Right_eye.columns=['Image','Labels']\n",
        "# Right_eye.to_csv(os.path.join(TRAIN_DIR,'right_eye.csv'))\n",
        "\n",
        "\n",
        "keywords_left=[keyword_l for keywords_left in df['Left-Diagnostic Keywords'] for keyword_l in keywords_left.split(',')]\n",
        "unique_keywords_left= set(keywords_left)\n",
        "# print((unique_keywords_left))\n",
        "# print(keywords_left[:10])\n",
        "\n",
        "keywords_right=[keyword_r for keywords_right in df['Right-Diagnostic Keywords'] for keyword_r in keywords_right.split(',')]\n",
        "unique_keywords_right= set(keywords_right)\n",
        "# print((unique_keywords_right))\n",
        "# print(keywords_right[:10])\n",
        "\n",
        "class_labels= ['N','D','C','A','F','M','O']\n",
        "keyword_label_mapping  = {\n",
        "    'normal':'N',\n",
        "    'retinopathy':'D',\n",
        "    'glaucoma':'G',\n",
        "    'cataract':'C',\n",
        "    'macular degeneration':'A',\n",
        "    'hypertensive':'H',\n",
        "    'myopia':'M',\n",
        "    'lens dust':'O', 'optic disk photographically invisible':'O', 'low image quality':'O', 'image offset':'O'\n",
        "}\n",
        "non_decisive_labels = [\"lens dust\", \"optic disk photographically invisible\", \"low image quality\", \"image offset\"]\n",
        "# print(get_individual_labels('optic disk photographically invisible'))\n",
        "\n",
        "df['Left-label']= df['Left-Diagnostic Keywords'].apply(get_individual_labels)\n",
        "df['Right-label'] = df['Right-Diagnostic Keywords'].apply(get_individual_labels)\n",
        "\n",
        "df[df['Left-label'].isin(non_decisive_labels)]\n",
        "df[df['Right-label'].isin(non_decisive_labels)]\n",
        "\n",
        "#for lefteye.csv\n",
        "\n",
        "# left_data= pd.read_csv(r'data\\left_eye.csv')\n",
        "# left_columns = 'left_labels'\n",
        "# l=[]\n",
        "# for left in left_data['Labels']:\n",
        "#      out_l= get_individual_labels(left)\n",
        "#      l.append(out_l)\n",
        "\n",
        "\n",
        "# left_data[left_columns]=l\n",
        "# # print(l)\n",
        "# left_data.to_csv(r'C:\\Users\\Dell\\Desktop\\grandchallenge\\data\\left_eye.csv',index=False)\n",
        "\n",
        "#for righteye.csv\n",
        "\n",
        "# right_data= pd.read_csv(r'data\\right_eye.csv')\n",
        "# right_columns = 'right_labels'\n",
        "# r=[]\n",
        "# for right in right_data['Labels']:\n",
        "#      out_r= get_individual_labels(right)\n",
        "#      r.append(out_r)\n",
        "\n",
        "\n",
        "# right_data[right_columns]=r\n",
        "# print(r)\n",
        "# right_data.to_csv(r'C:\\Users\\Dell\\Desktop\\grandchallenge\\data\\right_eye.csv',index=False)\n",
        "\n",
        "\n",
        "\n",
        "# find rows where both left and right have beeen processed as Normal, but the final diagnosis is not 'N\n",
        "df[df.apply(test_normal, axis=1) == False]\n",
        "# find rows where none of the left and right have been processed as Others, but the final diagnosis also contains 'O'\n",
        "df[df.apply(test_others,axis=1) == False]\n",
        "\n",
        "#transforms\n",
        "\n",
        "# img_paths = glob(f'{df}/*.jpg')\n",
        "# # len(img_paths)\n",
        "# for i in range(len(img_paths)//10):\n",
        "#     fig,ax = plt.subplots(1,2)\n",
        "#     img = plt.imread(img_paths[i*10])\n",
        "#     cropped_img = crop_nonzero(img)\n",
        "#     ax[0].imshow(img)\n",
        "#     ax[1].imshow(cropped_img)\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    # create a new dataframe where each row corresponds to one image\n",
        "left_fundus = df['Left-Fundus']\n",
        "left_label = df['Left-label']\n",
        "left_keywords = df['Left-Diagnostic Keywords']\n",
        "right_fundus = df['Right-Fundus']\n",
        "right_label = df['Right-label']\n",
        "right_keywords = df['Right-Diagnostic Keywords']\n",
        "id = df['ID']\n",
        "age = df['Patient Age']\n",
        "sex = df['Patient Sex']\n",
        "\n",
        "# separate train and test split\n",
        "\n",
        "SEED = 234\n",
        "id_train, id_val = train_test_split(id,test_size=0.1,random_state=SEED)\n",
        "\n",
        "train_left_fundus = df[df['ID'].isin(id_train)]['Left-Fundus']\n",
        "train_left_label = df[df['ID'].isin(id_train)]['Left-label']\n",
        "train_left_keywords = df[df['ID'].isin(id_train)]['Left-Diagnostic Keywords']\n",
        "\n",
        "train_right_fundus = df[df['ID'].isin(id_train)]['Right-Fundus']\n",
        "train_right_label = df[df['ID'].isin(id_train)]['Right-label']\n",
        "train_right_keywords = df[df['ID'].isin(id_train)]['Right-Diagnostic Keywords']\n",
        "\n",
        "\n",
        "val_left_fundus = df[df['ID'].isin(id_val)]['Left-Fundus']\n",
        "val_left_label = df[df['ID'].isin(id_val)]['Left-label']\n",
        "val_left_keywords = df[df['ID'].isin(id_val)]['Left-Diagnostic Keywords']\n",
        "\n",
        "val_right_fundus = df[df['ID'].isin(id_val)]['Right-Fundus']\n",
        "val_right_label = df[df['ID'].isin(id_val)]['Right-label']\n",
        "val_right_keywords = df[df['ID'].isin(id_val)]['Right-Diagnostic Keywords']\n",
        "\n",
        "# stack left and right columns vertically\n",
        "train_fundus = pd.concat([train_left_fundus, train_right_fundus],axis=0,ignore_index=True,sort=True)\n",
        "train_label = pd.concat([train_left_label,  train_right_label],axis=0,ignore_index=True,sort=True)\n",
        "train_keywords = pd.concat([train_left_keywords,train_right_keywords],axis=0,ignore_index=True,sort=True)\n",
        "\n",
        "val_fundus = pd.concat([val_left_fundus, val_right_fundus],axis=0,ignore_index=True)\n",
        "val_label = pd.concat([val_left_label,val_right_label],axis=0,ignore_index=True)\n",
        "val_keywords = pd.concat([val_left_keywords,val_right_keywords],axis=0,ignore_index=True)\n",
        "\n",
        "train_df_left_right_separate_row = pd.concat([train_fundus,\n",
        "                                              train_label,\n",
        "                                              train_keywords],axis=1,sort=True,\n",
        "                                              keys = ['fundus','label','keywords']) # stack horizontally\n",
        "val_df_left_right_separate_row = pd.concat([  val_fundus,\n",
        "                                              val_label,\n",
        "                                              val_keywords],axis=1,sort=True,\n",
        "                                              keys=['fundus','label','keywords']) # stack horizontally\n",
        "\n",
        "cleaned_train_df = train_df_left_right_separate_row.drop(train_df_left_right_separate_row[train_df_left_right_separate_row['label'].isin(non_decisive_labels)].index)\n",
        "cleaned_val_df = val_df_left_right_separate_row.drop(val_df_left_right_separate_row[val_df_left_right_separate_row['label'].isin(non_decisive_labels)].index)\n",
        "cleaned_train_df.to_csv('/content/drive/MyDrive/processed_train_.csv')\n",
        "cleaned_val_df.to_csv('/content/drive/MyDrive/processed_val-5K.csv')\n",
        "# len(df),len(id_train),len(id_val),len(train_fundus),len(val_fundus),len(train_df_left_right_separate_row),len(val_df_left_ri\n",
        "\n",
        "\n",
        "\n",
        "# test_root_dir = '../odir2019/ODIR-5K_Testing_Images'\n",
        "# test_paths = glob(f'{test_root_dir}/*.jpg')\n",
        "# test_paths = [ Path(p).name for p in test_paths]\n",
        "# test_df = DataFrame(data={'fundus':test_paths})\n",
        "# test_df.to_csv('../csv/processed_test_ODIR-5k.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8PVEku-phrQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6aG5apFhn7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtokvDxcgc3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transforms\n",
        "import numpy as np\n",
        "import  matplotlib as plt\n",
        "import torch\n",
        "import torchvision.io as io\n",
        "from torchvision.transforms import Lambda, Compose,ToTensor,Resize,Normalize\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms.functional as tvf\n",
        "from  torchvision.transforms import transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "def nonzero_bounding_box(img:np.ndarray, verbose=False):\n",
        "    '''\n",
        "    1. split the image into four quadrants: h_left_split, h_right_split, w_top_split, w_bottom_split\n",
        "    2. find the last non-zero pixel position for left and top splits\n",
        "    3. find the first non-zero pixel position for right and bottom splits\n",
        "    return the index of the above 4 values as bounding box (left,top,right,bottom)\n",
        "    '''\n",
        "    h,w,c = img.shape\n",
        "\n",
        "\n",
        "    # split image into four quadrants, use the first channel\n",
        "    left_half_axis_1d = img[h//2,:w//2,0].tolist()\n",
        "    top_half_axis_1d = img[:h//2,w//2,0].tolist()\n",
        "\n",
        "    right_half_axis_1d = img[h//2,w//2:,0].tolist()\n",
        "    bottom_half_axis_1d = img[h//2:,w//2,0].tolist()\n",
        "\n",
        "    # find first nonzero pixel positions, if no non-zero pixel positions exist, return lower-bounds and upper-bounds\n",
        "    try:\n",
        "        h_left = len(left_half_axis_1d) - left_half_axis_1d[::-1].index(0)\n",
        "    except ValueError as e:\n",
        "        # could not find zero in the list\n",
        "        h_left = 0\n",
        "\n",
        "    try:\n",
        "        w_top = len(top_half_axis_1d) - top_half_axis_1d[::-1].index(0)\n",
        "    except ValueError as e:\n",
        "        w_top = 0\n",
        "\n",
        "    try:\n",
        "        h_right = w//2 + right_half_axis_1d.index(0)\n",
        "    except ValueError as e:\n",
        "        h_right = h\n",
        "\n",
        "    try:\n",
        "        w_bottom = h//2 + bottom_half_axis_1d.index(0)\n",
        "    except ValueError as e:\n",
        "        w_bottom = w\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Image size {img.shape}')\n",
        "        print(h_left,h_right,w_top,w_bottom)\n",
        "    return h_left,h_right,w_top,w_bottom\n",
        "\n",
        "def crop_nonzero(img, verbose=False):\n",
        "    left, right, top, bottom = nonzero_bounding_box(img,verbose=verbose)\n",
        "    return img[top:bottom,left:right,:]\n",
        "\n",
        "def pad_to_largest_square(img:torch.Tensor,verbose=False):\n",
        "    c,h,w = img.shape\n",
        "    largest_side = max(img.shape)\n",
        "    if (largest_side - h) != 0 :\n",
        "        total_pad = largest_side - h\n",
        "        # this is the side where we need to pad\n",
        "        if total_pad % 2 == 0:\n",
        "            #even padding\n",
        "            top = bottom = total_pad // 2\n",
        "        else:\n",
        "            top = total_pad // 2\n",
        "            bottom = total_pad // 2 + 1\n",
        "    else:\n",
        "        top = bottom = 0\n",
        "\n",
        "    if (largest_side - w )!= 0:\n",
        "        total_pad = largest_side - w\n",
        "        # this is the side where we need to pad\n",
        "        if total_pad % 2 == 0:\n",
        "            # even padding\n",
        "            left = right = total_pad // 2\n",
        "        else:\n",
        "            # odd padding\n",
        "            left = total_pad // 2\n",
        "            right = total_pad // 2 + 1\n",
        "    else:\n",
        "        left = right = 0\n",
        "\n",
        "    required_pad = (left,top,right,bottom)\n",
        "    padded_img =  tvf.pad(img,required_pad,fill=0,padding_mode='constant')\n",
        "\n",
        "    if verbose:\n",
        "        print('Img shape',img.shape)\n",
        "        print('padding', required_pad)\n",
        "    return padded_img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def read_image(img_path):\n",
        "    # img_path = img.filename\n",
        "    # img = io.read_image(img_path)\n",
        "    # return img.copy() # return a copy to get rid of UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors.\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    return img.copy()\n",
        "    img_transform = Compose([\n",
        "    Lambda(read_image),\n",
        "    Lambda(crop_nonzero),\n",
        "    ToTensor(),\n",
        "    Lambda(pad_to_largest_square),\n",
        "    Normalize(mean= training_img_mean,std= torch.sqrt(training_img_var))\n",
        "])\n",
        "\n",
        "\n",
        "def get_img_transform(img_size:int):\n",
        "    base_img_transform = img_transform\n",
        "    resized_img_transform = Compose([\n",
        "        base_img_transform,\n",
        "        Resize(size=img_size,interpolation=tvf.InterpolationMode.BILINEAR,antialias=True,)\n",
        "\n",
        "    ])\n",
        "    return resized_img_transform\n",
        "\n",
        "def labels_to_idx(label):\n",
        "    return LABELS_TO_IDX[label]\n",
        "\n",
        "label_transform = Lambda(labels_to_idx)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "training_img_var = torch.Tensor([0.0713, 0.0345, 0.0140])\n",
        "training_img_mean = torch.Tensor([0.4384, 0.2866, 0.1646])\n",
        "\n",
        "LABELS  = ['N','D','G','C','A','H','M','O']\n",
        "LABELS_TO_IDX = {l:idx for idx, l in enumerate(LABELS)}"
      ],
      "metadata": {
        "id": "eZDSzzFVg79r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqcc4pEWg8_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJ-re-z_hAjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsfPCSeuhFzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "170vQZuyghOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrResEBDcw6I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_AKiO4yTWxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datasets\n",
        "# from transforms import labels_to_idx,read_image, get_img_transform\n",
        "\n",
        "# from preprocessing import ROOT_DIR\n",
        "from torch.utils.data import Dataset\n",
        "from os.path import join\n",
        "import csv\n",
        "# import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# TRAIN_DIR=r\"data\"\n",
        "def read_as_csv(csv_path):\n",
        "    file_name_arr=[]\n",
        "    label_arr=[]\n",
        "    with open(csv_path,'r') as f:\n",
        "        reader=csv.reader(f)\n",
        "        next(reader)\n",
        "        for row in reader:\n",
        "            file_name_arr.append(row[1])\n",
        "            label_arr.append(row[2])\n",
        "    return(file_name_arr,label_arr)\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self,csv_path,transforms:None):\n",
        "        images,labels=read_as_csv(csv_path)\n",
        "        self.images = images\n",
        "        self.labels=labels\n",
        "        self.transforms=transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<ImageDataset with {self.__len__()} samples>\"\n",
        "    def __getitem__(self,index):\n",
        "        # image=self.images[index]\n",
        "        # label=self.labels[index]\n",
        "        image_name=self.images[index]\n",
        "        label_name= self.labels[index]\n",
        "\n",
        "        image_path= join(\"/content/drive/MyDrive/ODIR-5K_Training_Dataset\",image_name)\n",
        "        # image= Image.open(image_path).convert('RGB')\n",
        "        label=labels_to_idx(label_name)\n",
        "        if self.transforms:\n",
        "            image= self.transforms(image_path)\n",
        "        return image,label\n"
      ],
      "metadata": {
        "id": "S--YBMHfgJAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge"
      ],
      "metadata": {
        "id": "zwsKuS2agNbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6958a1-7a96-4499-921f-b1fe80060b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files removed: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch-Ignite\n",
        "!pip install -q pytorch-ignite"
      ],
      "metadata": {
        "id": "QLsBJ6mMduH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9837527a-45a7-46e5-fbf6-791fe057c674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/272.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/272.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.4/272.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "in_colab = \"COLAB_TPU_ADDR\" in os.environ\n",
        "with_torchrun = \"WORLD_SIZE\" in os.environ\n",
        "\n",
        "if in_colab:\n",
        "    VERSION = !curl -s https://api.github.com/repos/pytorch/xla/releases/latest | grep -Po '\"tag_name\": \"v\\K.*?(?=\")'\n",
        "    !pip install --upgrade -q cloud-tpu-client==0.10 torch=={VERSION[0]} torchvision https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-{VERSION[0][:-2]}-cp38-cp38-linux_x86_64.whl\n",
        "\n",
        "!pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWwaRPuTPmoy",
        "outputId": "423c9963-f937-4f02-e85b-8c27bd0663e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch-ignite                   0.4.13\n",
            "torch                            2.1.0+cu121\n",
            "torchaudio                       2.1.0+cu121\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ignite"
      ],
      "metadata": {
        "id": "MoDKQ8aEgP4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-2hXyPI0bDHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloader\n",
        "# from datasets import ImageDataset\n",
        "# from transforms import  get_img_transform\n",
        "\n",
        "import tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import resnet18\n",
        "import ignite\n",
        "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from ignite.contrib.handlershandlers import TensorboardLogger, global_step_from_engine\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# BATCH_SIZE=16\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.model = resnet50(num_classes=8)\n",
        "\n",
        "        self.model.conv1 = self.model.conv1 = nn.Conv2d(\n",
        "            3, 64, kernel_size=3, padding=1, bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    ImageDataset(csv_path=r'C:\\Users\\Dell\\Desktop\\grandchallenge\\data\\processed_train_.csv' ,transforms= get_img_transform(img_size=(224, 224))),batch_size=5,shuffle=True)\n",
        "\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    ImageDataset(csv_path=r'C:\\Users\\Dell\\Desktop\\grandchallenge\\data\\processed_val-5K.csv',transforms=get_img_transform(img_size=(224, 224))),batch_size=5,shuffle=False\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = create_supervised_trainer(model, optimizer, criterion, device)\n",
        "\n",
        "val_metrics = {\n",
        "    \"accuracy\": Accuracy(),\n",
        "    \"loss\": Loss(criterion)\n",
        "}\n",
        "\n",
        "train_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
        "val_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "log_interval = 100\n",
        "\n",
        "@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
        "def log_training_loss(engine):\n",
        "    print(f\"Epoch[{engine.state.epoch}], Iter[{engine.state.iteration}] Loss: {engine.state.output:.2f}\")\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_training_results(trainer):\n",
        "    train_evaluator.run(train_loader)\n",
        "    metrics = train_evaluator.state.metrics\n",
        "    print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
        "\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_validation_results(trainer):\n",
        "    val_evaluator.run(val_loader)\n",
        "    metrics = val_evaluator.state.metrics\n",
        "    print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
        "\n",
        "\n",
        "def score_function(engine):\n",
        "    return engine.state.metrics[\"accuracy\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    \"checkpoint\",\n",
        "    n_saved=2,\n",
        "    filename_prefix=\"best\",\n",
        "    score_function=score_function,\n",
        "    score_name=\"accuracy\",\n",
        "    global_step_transform=global_step_from_engine(trainer),\n",
        "    require_empty= False\n",
        ")\n",
        "\n",
        "val_evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {\"model\": model})\n",
        "\n",
        "tb_logger = TensorboardLogger(log_dir=\"tb-logger\")\n",
        "\n",
        "tb_logger.attach_output_handler(\n",
        "    trainer,\n",
        "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
        "    tag=\"training\",\n",
        "    output_transform=lambda loss: {\"batch_loss\": loss},\n",
        ")\n",
        "\n",
        "for tag, evaluator in [(\"training\", train_evaluator), (\"validation\", val_evaluator)]:\n",
        "    tb_logger.attach_output_handler(\n",
        "        evaluator,\n",
        "        event_name=Events.EPOCH_COMPLETED,\n",
        "        tag=tag,\n",
        "        metric_names=\"all\",\n",
        "        global_step_transform=global_step_from_engine(trainer),\n",
        "    )\n",
        "\n",
        "trainer.run(train_loader, max_epochs=5)\n",
        "\n",
        "tb_logger.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IdjvhVQTe-65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "b98b25e2-a7d9-46ea-aa99-2e7ba6f6e7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ignite'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3aa9357f6a7e>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_supervised_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_supervised_evaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ignite'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip search pytorch-ignite"
      ],
      "metadata": {
        "id": "OziclYPyScBf",
        "outputId": "f8a7be23-316d-48a7-aa5b-fb6a01cf1e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: XMLRPC request failed [code: -32500]\n",
            "RuntimeError: PyPI no longer supports 'pip search' (or XML-RPC search). Please use https://pypi.org/search (via a browser) instead. See https://warehouse.pypa.io/api-reference/xml-rpc.html#deprecated-methods for more information.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bYIZDiVCfI-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x0acoRDrfLhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zQRk-gUJfVDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UpIfMkWcfVs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C_SBK79wfYqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7X8Mrpmfcuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s40ufI5Mfgch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}